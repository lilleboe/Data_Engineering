{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ETL Pipeline Comparing United States Immigration Data to City Demographics\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The Capstone project creates an ETL pipeline consisting of data from the [I94 immigration data](https://travel.trade.gov/research/reports/i94/historical/2016.html) and [US cities demographics data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/). The data is combined into a database that can be queried to answer questions concerning possible links between imigration and destination city and/or state demographics.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The project involves the selection of I94 immigration data to form the first dimension table.  The second dimension table utilizes US cities demographic data.  The two dimension tables will be joined on the state columns to form a fact table.  This fact table will display the total number of immigrants for each state and each states total population.  The fact table is designed to answer questions such as:\n",
    "* Which states have the most incoming immigrants?\n",
    "* Is there some correlation between number of immigrants and state populations?\n",
    "\n",
    "Spark is used as the engine to process data in the various tables.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The  [I94 immigration data](https://travel.trade.gov/research/reports/i94/historical/2016.html) is sourced from the US National Tourism and Trade Office. The format of the data is in SAS7BDAT which is a binary database storage format. \n",
    "\n",
    "The [US cities demographics data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/) is sourced from OpenSoft.  This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000.  This data comes from the US Census Bureau's 2015 American Community Survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read into Pandas April 2016 immigration data\n",
    "fname = \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    "df_immigration = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display some rows from the April 2016 imigration data for exploration and verification\n",
    "df_immigration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the city demographics data\n",
    "fname = \"./us-cities-demographics.csv\"\n",
    "df_cities = pd.read_csv(fname, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display some temperature data rows for exploration and verification\n",
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "There were values in the immigration data for the i94addr (State abbreviations) that contained Null (NaN) values.  This is an important column as it is the join conditon for creating the fact table; therefore, it was important to filter out Null values.  It was also stated in the documentation (I94_SAS_Labels_Descriptions.SAS) that a value of \"99\" was applied to rows proven to be invalid for this column value.  These values were also filtered out.  \n",
    "\n",
    "For the US demographic data, any state code column values having a Null (NaN) value were filtered out as this column is used to join in the fact table creation.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean the immigration data\n",
    "\n",
    "def clean_immigration_data(file):\n",
    "    '''\n",
    "        Input: The path to the immigration file\n",
    "        Output: Spark dataframe with valid columns of immigration data\n",
    "    '''\n",
    "    df_spark = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    df_spark = df_spark.filter((df_spark.i94addr.isNotNull()) & (df_spark.i94addr != \"99\") & (df_spark.visatype.isNotNull()))\n",
    "    return df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247103803E10|00602|      B1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the cleaning of the data\n",
    "\n",
    "test_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat' \n",
    "df_test = clean_immigration_data(test_file)\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean the city data\n",
    "cities_file = \"./us-cities-demographics.csv\"\n",
    "df_cities = spark.read.load(cities_file, format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "# Remove NULLs if found\n",
    "df_cities = df_cities.filter(df_cities['State code'].isNotNull()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|      Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|   California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|   New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "+----------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the cleaning of the data\n",
    "df_cities.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The immigration data dimension table contains data from the I94 immigration data.  The following columns are extracted from the source data:\n",
    "* i94yr   = year (4 digit value)\n",
    "* i94mon  = month (numeric value)\n",
    "* i94addr = destinatin state (State abbreviation) \n",
    "* i94cit  = origin city (3 digit value)\n",
    "* i94visa = Class of admission (text)\n",
    "\n",
    "The demographic data dimension table contains data from the US city demographic data set.  The following columns are extracted from the source data:\n",
    "* State Code = State abbreviation (text)\n",
    "* City = (text)\n",
    "* Race = (text)\n",
    "* Median Age = (decimal)\n",
    "* Male Population = (text)\n",
    "* Female Population = (text)\n",
    "* Number of Veterans = (integer)\n",
    "* Foreign-born = (integer)\n",
    "* Count = (integer)\n",
    "\n",
    "The fact table contains the joined information from the immigration and demographic dim tables.  The following columns compose the fact table:\n",
    "* State = (text)\n",
    "* Total_Immigrants = Total number of immigrants for that particular state (integer)\n",
    "* Total_Population = Total population of that state (based on cities with populations > 65K) (integer)\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1. Clean the source data.\n",
    "    * Call method clean_immigration_data on source data to clean I94 immigration data which creates Spark dataframe.\n",
    "    * From Step 2 clean the source city data which creates Spark dataframe df_cities.\n",
    "2. Create the immigration dimension table by selecting stated columns in section 3.1 from the Spark dataframe.  Write to parquet files which are partitioned by State.\n",
    "3. Create the demographics dimension table by selecting stated columns in section 3.1 from the Spark dataframe. Write to parquet files which are partitioned by State_Code. \n",
    "4. Create the fact table by joining the immigration and demographic dimension tables on the State and State_Code columns.  Write the results to parquet files partitioned by State."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Switch out the variables if you want a larger set of data\n",
    "#immigration_data = '/data/18-83510-I94-Data-2016/*.sas7bdat'\n",
    "im_data = '/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "# Clean I94 immigration data and store as Spark dataframe\n",
    "df_im = clean_immigration_data(im_data)\n",
    "\n",
    "# Extract columns, groupby and/or aggregate data for the dimension table\n",
    "im_dim_table = df_im.select(sf.col(\"i94yr\").alias(\"Year\"),\n",
    "                            sf.col(\"i94mon\").alias(\"Month\"),\n",
    "                            sf.col(\"i94addr\").alias(\"State\"), \n",
    "                            sf.col(\"i94cit\").alias(\"origin_city\"),\n",
    "                            sf.col(\"visatype\"))\n",
    "\n",
    "# Write the immigration dim table to parquet files partitioned by State\n",
    "im_dim_table.write.mode(\"append\").partitionBy(\"State\").parquet(\"/results/immigration_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Select a subset of the columns for the dim table\n",
    "cities_table = df_cities.select(sf.col(\"State Code\").alias(\"State_Code\"), \n",
    "                             sf.col(\"City\"), \n",
    "                             sf.col(\"Race\"),\n",
    "                             sf.col(\"Median Age\").alias(\"Median_Age\"),\n",
    "                             sf.col(\"Male Population\").alias(\"Male_Population\"),\n",
    "                             sf.col(\"Female Population\").alias(\"Female_Population\"),\n",
    "                             sf.col(\"Number of Veterans\").alias(\"Veterans\"),\n",
    "                             sf.col(\"Foreign-born\").alias(\"Foreign_born\"),\n",
    "                             sf.col(\"Count\"))\n",
    "\n",
    "# Write the state dem states table to parquet files partitioned by State Code\n",
    "cities_table.write.mode(\"append\").partitionBy(\"State_Code\").parquet(\"/results/state_counts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----------------+\n",
      "|State|Total_Immigrants|Total_Population|\n",
      "+-----+----------------+----------------+\n",
      "|   CA|          470386|        31753718|\n",
      "|   TX|          134321|        20029645|\n",
      "|   NY|          553677|        11377068|\n",
      "|   FL|          621701|         8664477|\n",
      "|   AZ|           20218|         5754881|\n",
      "+-----+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create some temp views\n",
    "im_dim_table.createOrReplaceTempView(\"immigration_view\")\n",
    "cities_table.createOrReplaceTempView(\"demographic_view\")\n",
    "\n",
    "# Create the fact table \n",
    "fact_table = spark.sql('''\n",
    "SELECT iv.State,\n",
    "       iv.Total_Immigrants,\n",
    "       dv.Total_Population\n",
    "FROM (SELECT State, COUNT(*) AS Total_Immigrants FROM immigration_view GROUP BY State) iv\n",
    "JOIN (SELECT State_Code, SUM(Count) AS Total_Population FROM demographic_view GROUP BY State_Code) dv\n",
    "    ON (iv.State = dv.State_Code)\n",
    "ORDER BY dv.Total_Population DESC\n",
    "''')\n",
    "\n",
    "# Write fact table to parquet files partitioned by State\n",
    "fact_table.write.mode(\"append\").partitionBy(\"State\").parquet(\"/results/fact.parquet\")\n",
    "fact_table.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "A data quality check method, data_quality_check, was created to look for the table counts.  The check simply verifies that the supplied Spark dataframe has at least 1 row of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for immigration table with 2943669 records\n",
      "Data quality check passed for demographic table with 2891 records\n",
      "Data quality check passed for fact table with 49 records\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_quality_check(df, desc):\n",
    "    '''\n",
    "    Input: Spark dataframe, description of Spark datafram\n",
    "    Output: Print outcome of data quality check\n",
    "    '''\n",
    "    \n",
    "    result_counts = df.count()\n",
    "    if result_counts == 0:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(desc))\n",
    "    else:\n",
    "        print(\"Data quality check passed for {} with {} records\".format(desc, result_counts))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check for dim and fact tables\n",
    "data_quality_check(im_dim_table, \"immigration table\")\n",
    "data_quality_check(cities_table, \"demographic table\")\n",
    "data_quality_check(fact_table, \"fact table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "The immigration data dimension table contains data from the I94 immigration data: \n",
    "* i94yr   = year (4 digit value)\n",
    "* i94mon  = month (numeric value)\n",
    "* i94addr = destinatin state (State abbreviation) \n",
    "* i94cit  = origin city (3 digit value)\n",
    "* i94visa = Class of admission (text)\n",
    "\n",
    "The demographic data dimension table contains data from the US city demographic data set: \n",
    "* State Code = State abbreviation (text)\n",
    "* City = City name (text)\n",
    "* Race = Racial category (text)\n",
    "* Median Age = Median age  for the particular city (decimal)\n",
    "* Male Population = The total number of males in the population for the particular city (text)\n",
    "* Female Population = The total number of females in the population for the particular city  (text)\n",
    "* Number of Veterans = Number of military veterns for the particular city  (integer)\n",
    "* Foreign-born = Number of foreign born for the particular city  (integer)\n",
    "* Count = Total number of people based on their racial category (integer)\n",
    "\n",
    "The fact table contains the joined information from the immigration and demographic dim tables.  The following columns compose the fact table:\n",
    "* State = State abbreviation (text)\n",
    "* Total_Immigrants = Total number of immigrants for that particular state (integer)\n",
    "* Total_Population = Total population of that state (based on cities with populations > 65K) (integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    * Spark was selected as the backbone technology for the project as it handles multiple large data file formats (SAS and CVS files).  The project also uses Spark SQL to process the large input data into dataframes.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "    * Since the immigration data set comes with a monthly subscription model that contains the latest month and year-to-date, updating the data monthly is suggested.  A higher frequency would not provide any new information at the expense of extra overhead.\n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     * With an increase of 100x the amount of data coming from the immigration dataset may prove to be prohibitly large to process in single batches.  Other third party tools may be required to help alleviate that increased data size.  We could consider using Spark in clustor mode.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     * Airflow might be a good choice if a daily update on a set schedule is required.  Airflow could manange the ETL pipeline and scheduling of the updating of the data.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     * The parquet files could be published to HDFS where the users could be granted access to read the data located there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
